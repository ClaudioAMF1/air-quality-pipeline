#!/bin/bash

echo "ğŸš€ Iniciando Pipeline Air Quality - Dataset Completo (6500+ registros)"
echo "=================================================================="

# Verificar se arquivo de dados existe
if [ ! -f "data/AirQualityUCI_Treated.csv" ]; then
    echo "âŒ ERRO: Arquivo data/AirQualityUCI_Treated.csv nÃ£o encontrado!"
    echo "ğŸ“ Certifique-se de que o arquivo completo estÃ¡ na pasta data/"
    echo "ğŸ’¡ O arquivo deve ter 6500+ linhas com dados atÃ© 04/04/2005"
    exit 1
fi

# Verificar tamanho do arquivo
file_size=$(du -h data/AirQualityUCI_Treated.csv | cut -f1)
line_count=$(wc -l < data/AirQualityUCI_Treated.csv)

echo "ğŸ“Š Verificando dataset:"
echo "   ğŸ“ Tamanho: $file_size"
echo "   ğŸ“„ Linhas: $line_count"

if [ $line_count -lt 1000 ]; then
    echo "âš ï¸  AVISO: Arquivo parece pequeno (menos de 1000 linhas)"
    echo "â“ Tem certeza de que Ã© o arquivo completo?"
    read -p "Continuar mesmo assim? (y/N): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        echo "âŒ ExecuÃ§Ã£o cancelada"
        exit 1
    fi
fi

cd docker

echo ""
echo "ğŸ›‘ Parando containers existentes..."
docker-compose down

echo ""
echo "ğŸ—ï¸  Construindo imagens customizadas..."
docker-compose build --no-cache

echo ""
echo "ğŸš€ Iniciando todos os serviÃ§os..."
docker-compose up -d

echo ""
echo "â³ Aguardando serviÃ§os ficarem prontos (3 minutos para grandes volumes)..."
echo "   â° Tempo estimado: 180 segundos"

for i in {1..18}; do
    echo -n "â³ $((i*10))s... "
    sleep 10
done
echo ""

echo ""
echo "ğŸ“‹ Status dos containers:"
docker-compose ps

echo ""
echo "ğŸ” Verificando conectividade..."
sleep 5

# Testar API
if curl -s http://localhost:5000/api/stats > /dev/null; then
    echo "âœ… API Flask: Conectada"
else
    echo "âŒ API Flask: NÃ£o respondendo"
fi

# Testar Streamlit
if curl -s http://localhost:8501 > /dev/null; then
    echo "âœ… Streamlit: Conectado"
else
    echo "âŒ Streamlit: NÃ£o respondendo"
fi

# Testar Airflow
if curl -s http://localhost:8080/health > /dev/null; then
    echo "âœ… Airflow: Conectado"
else
    echo "âŒ Airflow: NÃ£o respondendo"
fi

echo ""
echo "âœ… INFRAESTRUTURA INICIADA COM SUCESSO!"
echo ""
echo "ğŸŒ URLs dos serviÃ§os:"
echo "   ğŸ“Š Dashboard Streamlit: http://localhost:8501"
echo "   âš™ï¸  Airflow (OrquestraÃ§Ã£o): http://localhost:8080 (admin/admin)"
echo "   ğŸ”— API Flask: http://localhost:5000"
echo "   ğŸ° RabbitMQ Management: http://localhost:15672 (admin/admin)"
echo "   ğŸ’¾ MinIO Console: http://localhost:9001 (minioadmin/minioadmin)"
echo ""
echo "ğŸš€ PRÃ“XIMOS PASSOS:"
echo "   1. Acesse o Airflow: http://localhost:8080"
echo "   2. FaÃ§a login com: admin/admin"
echo "   3. Ative a DAG: 'air_quality_pipeline_full'"
echo "   4. Execute a DAG manualmente"
echo "   5. Acompanhe o dashboard: http://localhost:8501"
echo ""
echo "ğŸ“Š PROCESSAMENTO ESPERADO:"
echo "   ğŸ“ˆ O sistema processarÃ¡ $line_count registros"
echo "   â±ï¸  Tempo estimado: 10-15 minutos para dataset completo"
echo "   ğŸ’¾ SerÃ£o criados milhares de arquivos no MinIO"
echo "   ğŸš¨ Alertas crÃ­ticos serÃ£o detectados automaticamente"
echo ""
echo "ğŸ”§ Para monitorar:"
echo "   ./scripts/monitor.sh"
EOF

chmod +x scripts/start_infrastructure.sh