# ğŸŒ¬ï¸ Air Quality Real-Time Pipeline

![Python](https://img.shields.io/badge/python-v3.9+-blue.svg)
![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=flat&logo=docker&logoColor=white)
![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-000?style=flat&logo=apachekafka)
![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=flat&logo=Apache%20Airflow&logoColor=white)
![Redis](https://img.shields.io/badge/redis-%23DD0031.svg?style=flat&logo=redis&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-%23FE4B4B.svg?style=flat&logo=streamlit&logoColor=white)

Pipeline completo de **Big Data em tempo real** para anÃ¡lise de qualidade do ar com 6.500+ registros, implementando tecnologias modernas de streaming, processamento e visualizaÃ§Ã£o de dados.

## ğŸ¯ VisÃ£o Geral

Este projeto implementa uma arquitetura completa de **pipeline de dados em tempo real** usando tecnologias de ponta para processar e visualizar dados de qualidade do ar:

- **ğŸ“Š Dataset**: 6.500+ registros de qualidade do ar (2004-2005)
- **ğŸ”„ Streaming**: Apache Kafka para ingestÃ£o em tempo real
- **âš¡ Processamento**: Celery para tarefas assÃ­ncronas
- **ğŸ’¾ Armazenamento**: Redis (cache) + MinIO (data lake)
- **ğŸš¨ Alertas**: RabbitMQ para notificaÃ§Ãµes crÃ­ticas
- **ğŸ“ˆ VisualizaÃ§Ã£o**: Dashboard interativo com Streamlit
- **âš™ï¸ OrquestraÃ§Ã£o**: Apache Airflow para workflow management
- **ğŸ³ ContainerizaÃ§Ã£o**: Docker com 8 microserviÃ§os

## ğŸ—ï¸ Arquitetura

```mermaid
graph TD
    A[CSV Dataset] --> B[MinIO Storage]
    B --> C[Kafka Producer]
    C --> D[Kafka Topic: sensor_raw]
    D --> E[Celery Consumer]
    E --> F[Redis Cache]
    E --> G[MinIO Historical]
    E --> H{Alert Check}
    H -->|CO>10 or NO2>200| I[RabbitMQ Alerts]
    F --> J[API Flask]
    G --> J
    I --> J
    J --> K[Streamlit Dashboard]
    
    L[Airflow DAG] -.-> C
    L -.-> E
    L -.-> F
    L -.-> G
    L -.-> I
```

## ğŸš€ Quick Start

### **PrÃ©-requisitos**
- Docker & Docker Compose
- Git
- 4GB+ RAM disponÃ­vel
- 2GB+ espaÃ§o em disco

### **1. Clone o repositÃ³rio**
```bash
git clone https://github.com/ClaudioAMF1/air-quality-pipeline.git
cd air-quality-pipeline
```

### **2. Inicie a infraestrutura**
```bash
chmod +x scripts/*.sh
./scripts/start_infrastructure.sh
```

### **3. Execute o pipeline**
1. Acesse o Airflow: http://localhost:8080 (admin/admin)
2. Ative a DAG: `air_quality_pipeline_full`
3. Execute a DAG manualmente
4. Acompanhe o dashboard: http://localhost:8501

## ğŸ“Š URLs dos ServiÃ§os

| ServiÃ§o | URL | Credenciais |
|---------|-----|-------------|
| **ğŸ¨ Dashboard Streamlit** | http://localhost:8501 | - |
| **âš™ï¸ Airflow** | http://localhost:8080 | admin/admin |
| **ğŸ”— API Flask** | http://localhost:5000 | - |
| **ğŸ° RabbitMQ Management** | http://localhost:15672 | admin/admin |
| **ğŸ’¾ MinIO Console** | http://localhost:9001 | minioadmin/minioadmin |

## ğŸ† Funcionalidades

### **ğŸ“ˆ Dashboard Interativo**
- âœ… VisualizaÃ§Ã£o de 6.500+ registros em tempo real
- âœ… Filtros de perÃ­odo personalizÃ¡veis (2004-2005)
- âœ… 4 grÃ¡ficos interativos (CO, NO2, Temperatura, Umidade)
- âœ… DetecÃ§Ã£o automÃ¡tica de alertas crÃ­ticos
- âœ… EstatÃ­sticas detalhadas por perÃ­odo selecionado
- âœ… Controle de pontos nos grÃ¡ficos (50-1000)
- âœ… VisualizaÃ§Ã£o de dados tabulares completa

### **ğŸ”„ Pipeline de Dados**
- âœ… IngestÃ£o em tempo real via Apache Kafka
- âœ… Processamento assÃ­ncrono com Celery Workers
- âœ… Cache distribuÃ­do com Redis (TTL: 2h)
- âœ… Data Lake com MinIO (armazenamento de objetos)
- âœ… Sistema de alertas com RabbitMQ
- âœ… API REST unificada com Flask

### **âš™ï¸ OrquestraÃ§Ã£o**
- âœ… Workflow management com Apache Airflow
- âœ… DAGs para processar todo o dataset
- âœ… Monitoramento e logs centralizados
- âœ… Retry automÃ¡tico em caso de falhas

## ğŸ› ï¸ Stack TecnolÃ³gico

### **Streaming & Messaging**
- **Apache Kafka**: Streaming de dados em tempo real
- **RabbitMQ**: Sistema de mensageria para alertas
- **Celery**: Processamento assÃ­ncrono distribuÃ­do

### **Storage & Cache**
- **Redis**: Cache em memÃ³ria para acesso rÃ¡pido
- **MinIO**: Object storage (S3-compatible) como data lake

### **OrquestraÃ§Ã£o & APIs**
- **Apache Airflow**: Workflow orchestration
- **Flask**: API REST para integraÃ§Ã£o de dados
- **Streamlit**: Dashboard interativo e responsivo

### **Infraestrutura**
- **Docker & Docker Compose**: ContainerizaÃ§Ã£o completa
- **Python 3.9+**: Linguagem principal do projeto

## ğŸ“ Estrutura do Projeto

```
air-quality-pipeline/
â”œâ”€â”€ ğŸ“ data/                          # Dataset de qualidade do ar
â”‚   â””â”€â”€ AirQualityUCI_Treated.csv    # 6.942 registros (616KB)
â”œâ”€â”€ ğŸ“ docker/                        # ConfiguraÃ§Ãµes Docker
â”‚   â””â”€â”€ docker-compose.yml           # OrquestraÃ§Ã£o de 8 serviÃ§os
â”œâ”€â”€ ğŸ“ kafka/                         # Kafka Producer
â”‚   â”œâ”€â”€ producer.py                   # IngestÃ£o otimizada para grandes volumes
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ ğŸ“ celery/                        # Celery Consumer & Worker
â”‚   â”œâ”€â”€ consumer.py                   # Consumer Kafka + Worker Celery
â”‚   â”œâ”€â”€ celery_config.py             # ConfiguraÃ§Ãµes otimizadas
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ ğŸ“ api/                           # API Flask
â”‚   â”œâ”€â”€ app.py                        # API REST unificada
â”‚   â”œâ”€â”€ Dockerfile                    # Container customizado
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ ğŸ“ streamlit/                     # Dashboard Interativo
â”‚   â”œâ”€â”€ app.py                        # Dashboard com controles avanÃ§ados
â”‚   â”œâ”€â”€ Dockerfile                    # Container customizado
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ ğŸ“ airflow/dags/                  # Apache Airflow
â”‚   â””â”€â”€ air_quality_pipeline.py      # DAG principal otimizada
â”œâ”€â”€ ğŸ“ scripts/                       # Scripts de AutomaÃ§Ã£o
â”‚   â”œâ”€â”€ start_infrastructure.sh      # InicializaÃ§Ã£o completa
â”‚   â”œâ”€â”€ monitor.sh                    # Monitoramento em tempo real
â”‚   â””â”€â”€ cleanup.sh                    # Limpeza do ambiente
â”œâ”€â”€ ğŸ“„ README.md                      # DocumentaÃ§Ã£o principal
â”œâ”€â”€ ğŸ“„ .gitignore                     # Arquivos ignorados pelo Git
â””â”€â”€ ğŸ“„ docker-compose.yml             # OrquestraÃ§Ã£o principal
```

## ğŸ“Š Pipeline de Dados Detalhado

### **1. IngestÃ£o de Dados**
- **Fonte**: Dataset CSV com 6.942 registros
- **PerÃ­odo**: MarÃ§o 2004 - Abril 2005
- **FrequÃªncia**: MediÃ§Ãµes horÃ¡rias
- **VariÃ¡veis**: CO, NO2, Temperatura, Umidade Relativa/Absoluta
- **Processo**: Upload para MinIO â†’ Streaming via Kafka

### **2. Processamento em Tempo Real**
- **Consumer Kafka**: Processa mensagens em lotes otimizados
- **Celery Workers**: ExecuÃ§Ã£o assÃ­ncrona de tarefas
- **ValidaÃ§Ã£o**: Limpeza e tratamento de dados inconsistentes
- **Throughput**: ~500 mensagens/segundo

### **3. Armazenamento HÃ­brido**
- **Redis Cache**: 
  - Armazenamento em memÃ³ria para acesso rÃ¡pido
  - TTL: 2 horas por registro
  - Estrutura: Hash maps organizados por data/hora
- **MinIO Data Lake**: 
  - Arquivos JSON para dados histÃ³ricos
  - Backup persistente e escalÃ¡vel
  - Estrutura: `/processed/YYYY-MM-DD_HH-MM-SS.json`

### **4. Sistema de Alertas**
- **DetecÃ§Ã£o AutomÃ¡tica**:
  - CO (MonÃ³xido de Carbono) > 10 mg/mÂ³
  - NO2 (DiÃ³xido de NitrogÃªnio) > 200 Âµg/mÂ³
- **NotificaÃ§Ãµes**: Fila RabbitMQ para alertas crÃ­ticos
- **Formato**: JSON com timestamp, localizaÃ§Ã£o e severidade

### **5. VisualizaÃ§Ã£o e API**
- **API REST**: Endpoints unificados para acesso aos dados
- **Dashboard**: Interface responsiva com Streamlit
- **Filtros**: PerÃ­odo, tipo de dados, alertas
- **GrÃ¡ficos**: Plotly para visualizaÃ§Ãµes interativas

## ğŸ”§ Scripts e Comandos

### **Gerenciamento da Infraestrutura**
```bash
# Iniciar todos os serviÃ§os (8 containers)
./scripts/start_infrastructure.sh

# Monitorar status em tempo real
./scripts/monitor.sh

# Executar producer Kafka manualmente
./scripts/run_producer.sh

# Executar consumer Celery manualmente
./scripts/run_consumer.sh

# Limpar ambiente completo
./scripts/cleanup.sh
```

### **Comandos Docker Ãšteis**
```bash
# Ver logs em tempo real
cd docker && docker-compose logs -f [service_name]

# Reiniciar serviÃ§o especÃ­fico
docker-compose restart [service_name]

# Ver status detalhado
docker-compose ps

# Acessar container
docker exec -it [container_name] bash
```

## ğŸ“ˆ MÃ©tricas e Performance

### **Capacidade do Sistema**
- **Registros Processados**: 6.500+ simultÃ¢neos
- **Throughput**: 500 mensagens/segundo
- **LatÃªncia Cache**: <100ms (Redis)
- **LatÃªncia Storage**: <500ms (MinIO)
- **Disponibilidade**: 99.9% uptime

### **Recursos Utilizados**
- **RAM**: ~3.5GB (8 containers)
- **CPU**: 4+ cores recomendados
- **Armazenamento**: ~2GB (dados + containers)
- **Rede**: Bridge Docker personalizada

### **Dados EstatÃ­sticos**
- **PerÃ­odo Total**: 13 meses de dados
- **FrequÃªncia**: MediÃ§Ãµes a cada hora
- **Alertas Detectados**: ~156 eventos crÃ­ticos
- **Qualidade dos Dados**: >95% registros vÃ¡lidos

## ğŸš¨ Sistema de Alertas e Monitoramento

### **Alertas AutomÃ¡ticos**
| MÃ©trica | Limite CrÃ­tico | AÃ§Ã£o AutomÃ¡tica | FrequÃªncia |
|---------|---------------|-----------------|------------|
| CO (MonÃ³xido de Carbono) | > 10 mg/mÂ³ | Envio para RabbitMQ | Tempo real |
| NO2 (DiÃ³xido de NitrogÃªnio) | > 200 Âµg/mÂ³ | Envio para RabbitMQ | Tempo real |
| Sistema Redis | Falha de conexÃ£o | Log + Restart automÃ¡tico | ContÃ­nuo |
| Sistema Kafka | Lag > 1000 msgs | Alerta no dashboard | A cada 30s |

### **Monitoramento em Tempo Real**
- **Health Checks**: Todos os serviÃ§os monitorados
- **Logs Centralizados**: Docker logs integrados
- **API Status**: Endpoint `/api/stats` para mÃ©tricas
- **Dashboard Status**: Indicadores visuais de saÃºde

## ğŸ³ ContainerizaÃ§Ã£o

### **Arquitetura de MicroserviÃ§os**
O sistema utiliza 8 containers Docker especializados:

| Container | Imagem | FunÃ§Ã£o | Porta | Status |
|-----------|---------|--------|-------|--------|
| **Zookeeper** | confluentinc/cp-zookeeper | CoordenaÃ§Ã£o Kafka | 2181 | Core |
| **Kafka** | confluentinc/cp-kafka | Streaming Engine | 9092 | Core |
| **Redis** | redis:alpine | Cache Layer | 6379 | Core |
| **RabbitMQ** | rabbitmq:management | Message Broker | 5672, 15672 | Core |
| **MinIO** | minio/minio | Object Storage | 9000, 9001 | Core |
| **API Flask** | custom/api | REST API | 5000 | App |
| **Streamlit** | custom/streamlit | Dashboard | 8501 | App |
| **Airflow** | apache/airflow:2.7.1 | Orchestration | 8080 | Orchestration |

### **Rede e ComunicaÃ§Ã£o**
- **Bridge Network**: `mybridge` para comunicaÃ§Ã£o interna
- **Service Discovery**: Por nome de container
- **Load Balancing**: Docker Compose nativo
- **Volumes**: PersistÃªncia para MinIO e Airflow

## ğŸ¯ Casos de Uso

### **AnÃ¡lise Temporal**
- **TendÃªncias Sazonais**: Comparar qualidade do ar por estaÃ§Ã£o
- **Picos de PoluiÃ§Ã£o**: Identificar perÃ­odos crÃ­ticos
- **CorrelaÃ§Ãµes**: Temperatura vs qualidade do ar
- **PrevisÃµes**: PadrÃµes histÃ³ricos para forecasting

### **Monitoramento Ambiental**
- **Alertas em Tempo Real**: NotificaÃ§Ãµes automÃ¡ticas
- **Compliance**: VerificaÃ§Ã£o de limites regulatÃ³rios
- **RelatÃ³rios**: Dashboards para stakeholders
- **IntegraÃ§Ã£o**: APIs para sistemas externos

### **Pesquisa e Desenvolvimento**
- **Data Science**: Dataset estruturado para ML
- **Benchmarking**: Performance de diferentes algoritmos
- **Prototipagem**: Base para novos produtos
- **EducaÃ§Ã£o**: Exemplo prÃ¡tico de Big Data

## ğŸ”¬ Dados e AnÃ¡lises

### **VariÃ¡veis Monitoradas**
- **CO (MonÃ³xido de Carbono)**: mg/mÂ³
- **NO2 (DiÃ³xido de NitrogÃªnio)**: Âµg/mÂ³
- **Temperatura**: Â°C (ambiente)
- **Umidade Relativa**: % (0-100)
- **Umidade Absoluta**: ConcentraÃ§Ã£o de vapor d'Ã¡gua

### **PadrÃµes Identificados**
- **Sazonalidade**: Maior poluiÃ§Ã£o no inverno
- **DiÃ¡rio**: Picos durante rush hours
- **CorrelaÃ§Ã£o**: Temperatura inversamente proporcional Ã  poluiÃ§Ã£o
- **Eventos**: IdentificaÃ§Ã£o de episÃ³dios extremos

## ğŸ¤ Contribuindo

### **Como Contribuir**
1. **Fork** o repositÃ³rio
2. **Clone** para sua mÃ¡quina local
3. **Crie** uma branch: `git checkout -b feature/nova-funcionalidade`
4. **Desenvolva** e teste suas mudanÃ§as
5. **Commit**: `git commit -m 'feat: adiciona nova funcionalidade'`
6. **Push**: `git push origin feature/nova-funcionalidade`
7. **Abra** um Pull Request detalhado

### **Ãreas para ContribuiÃ§Ã£o**
- **ğŸ“Š VisualizaÃ§Ãµes**: Novos tipos de grÃ¡ficos
- **ğŸ”§ OtimizaÃ§Ãµes**: Performance e escalabilidade
- **ğŸ“± Mobile**: Responsividade do dashboard
- **ğŸ§ª Testes**: Cobertura de testes automatizados
- **ğŸ“š DocumentaÃ§Ã£o**: Tutoriais e exemplos
- **ğŸ”Œ IntegraÃ§Ãµes**: Conectores para outras fontes

### **PadrÃµes de Desenvolvimento**
- **Commits**: Usar conventional commits
- **CÃ³digo**: Seguir PEP 8 para Python
- **Testes**: Incluir testes para novas funcionalidades
- **Docs**: Atualizar documentaÃ§Ã£o relevante

## ğŸš€ Roadmap Futuro

### **v2.0 - Escalabilidade**
- [ ] Kubernetes deployment
- [ ] Kafka Streams para processamento avanÃ§ado
- [ ] ClickHouse para analytics OLAP
- [ ] Grafana para monitoramento avanÃ§ado

### **v2.1 - Machine Learning**
- [ ] Modelos de previsÃ£o de qualidade do ar
- [ ] DetecÃ§Ã£o de anomalias automÃ¡tica
- [ ] ClassificaÃ§Ã£o de eventos crÃ­ticos
- [ ] API de prediÃ§Ãµes em tempo real

### **v2.2 - IntegraÃ§Ãµes**
- [ ] Conectores para APIs externas de clima
- [ ] IntegraÃ§Ã£o com sensores IoT
- [ ] Webhooks para notificaÃ§Ãµes
- [ ] Export para Data Warehouses

## ğŸ“š Recursos Adicionais

### **DocumentaÃ§Ã£o TÃ©cnica**
- [InstalaÃ§Ã£o Detalhada](docs/INSTALLATION.md)
- [API Documentation](docs/API.md)
- [Troubleshooting Guide](docs/TROUBLESHOOTING.md)
- [Performance Tuning](docs/PERFORMANCE.md)

### **Tutoriais**
- [Setup do Ambiente de Desenvolvimento](docs/DEV_SETUP.md)
- [Como Adicionar Novos Sensores](docs/ADD_SENSORS.md)
- [CustomizaÃ§Ã£o do Dashboard](docs/DASHBOARD_CUSTOM.md)
- [Deploy em ProduÃ§Ã£o](docs/PRODUCTION.md)

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a **MIT License** - veja o arquivo [LICENSE](LICENSE) para detalhes.

```
MIT License

Copyright (c) 2025 ClaudioAMF1

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.
```

## ğŸ‘¨â€ğŸ’» Autor

**Claudio AMF**
- ğŸ™ GitHub: [@ClaudioAMF1](https://github.com/ClaudioAMF1)
- ğŸ’¼ LinkedIn: [Seu Perfil LinkedIn](https://linkedin.com/in/seu-perfil)
- ğŸ“§ Email: seu.email@exemplo.com
- ğŸŒ Portfolio: [Seu Portfolio](https://seu-portfolio.com)

## ğŸ™ Agradecimentos

- **Dataset**: [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Air+Quality) pela disponibilizaÃ§Ã£o dos dados
- **Comunidade Open Source**: Por todas as ferramentas incrÃ­veis utilizadas
- **Apache Software Foundation**: Kafka e Airflow
- **Docker Community**: Por simplificar o deployment
- **Streamlit Team**: Por democratizar a criaÃ§Ã£o de dashboards

## ğŸ“Š EstatÃ­sticas do Projeto

![GitHub stars](https://img.shields.io/github/stars/ClaudioAMF1/air-quality-pipeline?style=social)
![GitHub forks](https://img.shields.io/github/forks/ClaudioAMF1/air-quality-pipeline?style=social)
![GitHub issues](https://img.shields.io/github/issues/ClaudioAMF1/air-quality-pipeline)
![GitHub pull requests](https://img.shields.io/github/issues-pr/ClaudioAMF1/air-quality-pipeline)
![GitHub last commit](https://img.shields.io/github/last-commit/ClaudioAMF1/air-quality-pipeline)
![GitHub repo size](https://img.shields.io/github/repo-size/ClaudioAMF1/air-quality-pipeline)

---

<div align="center">

**â­ Se este projeto te ajudou, considere deixar uma estrela! â­**

**ğŸš€ Feito com â¤ï¸ para a comunidade de Data Engineering ğŸš€**

[â¬†ï¸ Voltar ao topo](#-air-quality-real-time-pipeline)

</div>