import streamlit as st
import requests
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import time
import json
from datetime import datetime, date
import numpy as np

# ConfiguraÃ§Ãµes da pÃ¡gina
st.set_page_config(
    page_title="Air Quality Monitor",
    page_icon="ğŸŒ¬ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ConfiguraÃ§Ãµes da API
API_BASE_URL = "http://api:5000/api"

def get_api_data(endpoint):
    """Fazer requisiÃ§Ã£o para a API"""
    try:
        response = requests.get(f"{API_BASE_URL}/{endpoint}", timeout=10)
        if response.status_code == 200:
            return response.json()
        else:
            return None
    except Exception as e:
        st.error(f"Erro ao conectar com a API: {e}")
        return None

def clean_and_convert_dates(df):
    """Limpar e converter datas com mÃºltiplas estratÃ©gias"""
    if df.empty:
        return df
    
    try:
        st.write(f"ğŸ” **Debug**: Processando {len(df)} registros...")
        
        # Mostrar algumas amostras de datas para debug
        if len(df) > 0:
            sample_dates = df[['date', 'time']].head(3)
            st.write("ğŸ“ **Amostra de datas:**")
            st.dataframe(sample_dates)
        
        # EstratÃ©gia 1: Tentar formato padrÃ£o
        df['datetime'] = pd.to_datetime(df['date'] + ' ' + df['time'], errors='coerce')
        
        # EstratÃ©gia 2: Se muitos NaT, tentar formato brasileiro
        nat_count = df['datetime'].isna().sum()
        if nat_count > len(df) * 0.5:  # Se mais de 50% sÃ£o NaT
            st.warning(f"âš ï¸ {nat_count} datas invÃ¡lidas no formato padrÃ£o, tentando formato brasileiro...")
            df['datetime'] = pd.to_datetime(df['date'] + ' ' + df['time'], 
                                          format='%d/%m/%Y %H.%M.%S', errors='coerce')
        
        # EstratÃ©gia 3: Tentar outros formatos comuns
        nat_count_after = df['datetime'].isna().sum()
        if nat_count_after > len(df) * 0.5:
            st.warning(f"âš ï¸ Ainda {nat_count_after} datas invÃ¡lidas, tentando mais formatos...")
            # Tentar com diferentes separadores
            for fmt in ['%d/%m/%Y %H:%M:%S', '%Y-%m-%d %H:%M:%S', '%d-%m-%Y %H:%M:%S']:
                mask = df['datetime'].isna()
                if mask.any():
                    df.loc[mask, 'datetime'] = pd.to_datetime(
                        df.loc[mask, 'date'] + ' ' + df.loc[mask, 'time'], 
                        format=fmt, errors='coerce'
                    )
        
        # Contar quantos dados vÃ¡lidos temos
        valid_count = df['datetime'].notna().sum()
        invalid_count = df['datetime'].isna().sum()
        
        st.write(f"âœ… **Resultado da conversÃ£o:**")
        st.write(f"   - Datas vÃ¡lidas: {valid_count}")
        st.write(f"   - Datas invÃ¡lidas: {invalid_count}")
        
        # Se temos pelo menos alguns dados vÃ¡lidos, continuar
        if valid_count > 0:
            # Remover apenas registros com datetime invÃ¡lido
            df_clean = df.dropna(subset=['datetime']).copy()
            df_clean = df_clean.sort_values('datetime', ascending=True)
            
            st.success(f"ğŸ‰ **{len(df_clean)} registros vÃ¡lidos** prontos para anÃ¡lise!")
            return df_clean
        else:
            st.error("âŒ Nenhuma data vÃ¡lida encontrada em nenhum formato")
            return pd.DataFrame()
        
    except Exception as e:
        st.error(f"Erro ao processar datas: {e}")
        st.write("ğŸ”§ **Fallback**: Usando dados sem filtro de data...")
        # Retornar dados originais sem datetime para pelo menos mostrar algo
        return df

def filter_data_by_period(df, start_date, end_date):
    """Filtrar dados por perÃ­odo"""
    if df.empty or 'datetime' not in df.columns:
        return df
    
    try:
        mask = (df['datetime'].dt.date >= start_date) & (df['datetime'].dt.date <= end_date)
        return df[mask].copy()
    except Exception as e:
        st.error(f"Erro ao filtrar dados: {e}")
        return df

def main():
    """FunÃ§Ã£o principal do dashboard"""
    
    # TÃ­tulo principal
    st.title("ğŸŒ¬ï¸ Air Quality Real-Time Monitor - Dataset Completo")
    st.markdown("---")
    
    # Sidebar para controles
    st.sidebar.title("âš™ï¸ Controles")
    
    # Auto-refresh
    auto_refresh = st.sidebar.checkbox("Auto Refresh (30s)", value=False)
    
    if st.sidebar.button("ğŸ”„ Atualizar Agora"):
        st.rerun()
    
    # Mostrar estatÃ­sticas gerais primeiro
    st.subheader("ğŸ“Š EstatÃ­sticas do Sistema")
    
    stats = get_api_data("stats")
    if stats:
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Cache Records", stats.get('cache_records', 0))
        with col2:
            st.metric("Historical Files", stats.get('historical_files', 0))
        with col3:
            st.metric("Pending Alerts", stats.get('pending_alerts', 0))
        with col4:
            st.metric("System Status", "ğŸŸ¢ Online" if stats else "ğŸ”´ Offline")
    
    st.markdown("---")
    
    # Carregar dados
    with st.spinner("ğŸ“¡ Carregando dados da API..."):
        cache_data = get_api_data("cache")
    
    if cache_data and cache_data.get('data'):
        try:
            df_cache = pd.DataFrame(cache_data['data'])
            st.success(f"âœ… **{len(df_cache)} registros** carregados da API")
            
            # Converter colunas numÃ©ricas
            numeric_cols = ['CO', 'NO2', 'Temperature', 'Relative_Humidity', 'Absolute_Humidity']
            for col in numeric_cols:
                if col in df_cache.columns:
                    df_cache[col] = pd.to_numeric(df_cache[col], errors='coerce')
            
            # Limpar e converter datas
            with st.expander("ğŸ”§ Debug: Processamento de Datas", expanded=False):
                df_cache = clean_and_convert_dates(df_cache)
            
            if df_cache.empty:
                st.error("âŒ Nenhum dado vÃ¡lido apÃ³s processamento")
                # Mostrar dados brutos pelo menos
                st.subheader("ğŸ“‹ Dados Brutos (sem filtro de data)")
                raw_df = pd.DataFrame(cache_data['data'])
                display_df = raw_df.drop(columns=['cache_key', 'timestamp'], errors='ignore').head(50)
                st.dataframe(display_df, use_container_width=True)
                return
            
            # Se temos datetime vÃ¡lido, mostrar controles de perÃ­odo
            if 'datetime' in df_cache.columns and df_cache['datetime'].notna().any():
                # Obter datas mÃ­n/mÃ¡x vÃ¡lidas
                min_date = df_cache['datetime'].min().date()
                max_date = df_cache['datetime'].max().date()
                
                # Filtros de perÃ­odo na sidebar
                st.sidebar.markdown("---")
                st.sidebar.subheader("ğŸ“… Filtro de PerÃ­odo")
                
                st.sidebar.write(f"**Dados disponÃ­veis:**")
                st.sidebar.write(f"ğŸ“… De: {min_date}")
                st.sidebar.write(f"ğŸ“… AtÃ©: {max_date}")
                
                # Seletores de data
                col1, col2 = st.sidebar.columns(2)
                with col1:
                    start_date = st.date_input(
                        "Data Inicial", 
                        value=min_date, 
                        min_value=min_date, 
                        max_value=max_date
                    )
                with col2:
                    end_date = st.date_input(
                        "Data Final", 
                        value=max_date, 
                        min_value=min_date, 
                        max_value=max_date
                    )
                
                # Filtrar dados pelo perÃ­odo
                df_filtered = filter_data_by_period(df_cache, start_date, end_date)
            else:
                # Usar todos os dados sem filtro
                df_filtered = df_cache
                start_date = "N/A"
                end_date = "N/A"
            
            # OpÃ§Ãµes de visualizaÃ§Ã£o
            st.sidebar.markdown("---")
            st.sidebar.subheader("ğŸ“Š OpÃ§Ãµes de VisualizaÃ§Ã£o")
            show_all_data = st.sidebar.checkbox("Mostrar todos os registros na tabela", value=False)
            max_graph_points = st.sidebar.slider("Pontos mÃ¡ximos nos grÃ¡ficos", 50, 1000, 200)
            
        except Exception as e:
            st.error(f"Erro ao processar dados: {e}")
            df_filtered = pd.DataFrame()
            start_date = "Erro"
            end_date = "Erro"
    else:
        df_filtered = pd.DataFrame()
        start_date = "N/A"
        end_date = "N/A"
    
    # SeÃ§Ã£o de dados
    if not df_filtered.empty:
        total_records = len(df_cache) if 'df_cache' in locals() else len(df_filtered)
        filtered_records = len(df_filtered)
        
        st.subheader(f"âš¡ Dados Processados ({start_date} atÃ© {end_date})")
        
        # InformaÃ§Ãµes do perÃ­odo
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Total Carregado", f"{total_records:,}")
        with col2:
            st.metric("Registros VÃ¡lidos", f"{filtered_records:,}")
        with col3:
            percentage = (filtered_records / total_records * 100) if total_records > 0 else 0
            st.metric("% VÃ¡lido", f"{percentage:.1f}%")
        with col4:
            if isinstance(start_date, date) and isinstance(end_date, date):
                days = (end_date - start_date).days + 1
                st.metric("Dias", days)
            else:
                st.metric("Status", "Sem filtro de data")
        
        # Tabela de dados
        st.subheader("ğŸ“‹ Dados Tabulares")
        
        if show_all_data:
            st.write(f"**Mostrando todos os {filtered_records} registros:**")
            display_df = df_filtered.drop(columns=['cache_key', 'datetime', 'timestamp'], errors='ignore')
            st.dataframe(display_df, use_container_width=True, height=400)
        else:
            st.write(f"**Mostrando Ãºltimos 50 de {filtered_records} registros:**")
            display_df = df_filtered.tail(50).drop(columns=['cache_key', 'datetime', 'timestamp'], errors='ignore')
            st.dataframe(display_df, use_container_width=True)
        
        # GrÃ¡ficos simples (mesmo sem datetime)
        if len(df_filtered) > 1:
            # Preparar dados para grÃ¡fico
            if len(df_filtered) > max_graph_points:
                step = len(df_filtered) // max_graph_points
                plot_data = df_filtered.iloc[::step].copy()
                st.info(f"ğŸ“Š Mostrando {len(plot_data)} pontos de {len(df_filtered)} disponÃ­veis")
            else:
                plot_data = df_filtered.copy()
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("ï¿½ï¿½ MonÃ³xido de Carbono (CO)")
                if 'datetime' in plot_data.columns:
                    fig_co = px.line(plot_data, x='datetime', y='CO', title="NÃ­veis de CO")
                else:
                    fig_co = px.line(plot_data.reset_index(), x='index', y='CO', title="NÃ­veis de CO (por registro)")
                fig_co.add_hline(y=10, line_dash="dash", line_color="red", annotation_text="CrÃ­tico (10)")
                st.plotly_chart(fig_co, use_container_width=True)
            
            with col2:
                st.subheader("ğŸŸ¦ DiÃ³xido de NitrogÃªnio (NO2)")
                if 'datetime' in plot_data.columns:
                    fig_no2 = px.line(plot_data, x='datetime', y='NO2', title="NÃ­veis de NO2")
                else:
                    fig_no2 = px.line(plot_data.reset_index(), x='index', y='NO2', title="NÃ­veis de NO2 (por registro)")
                fig_no2.add_hline(y=200, line_dash="dash", line_color="red", annotation_text="CrÃ­tico (200)")
                st.plotly_chart(fig_no2, use_container_width=True)
            
            # EstatÃ­sticas
            st.subheader("ğŸ“ˆ EstatÃ­sticas dos Dados")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                co_stats = df_filtered['CO'].describe()
                st.metric("CO MÃ©dio", f"{co_stats['mean']:.2f}")
                st.caption(f"Min: {co_stats['min']:.2f} | Max: {co_stats['max']:.2f}")
                critical_co = len(df_filtered[df_filtered['CO'] > 10])
                st.caption(f"ğŸš¨ CrÃ­ticos: {critical_co}")
            
            with col2:
                no2_stats = df_filtered['NO2'].describe()
                st.metric("NO2 MÃ©dio", f"{no2_stats['mean']:.2f}")
                st.caption(f"Min: {no2_stats['min']:.2f} | Max: {no2_stats['max']:.2f}")
                critical_no2 = len(df_filtered[df_filtered['NO2'] > 200])
                st.caption(f"ğŸš¨ CrÃ­ticos: {critical_no2}")
            
            with col3:
                temp_stats = df_filtered['Temperature'].describe()
                st.metric("Temp MÃ©dia", f"{temp_stats['mean']:.1f}Â°C")
                st.caption(f"Min: {temp_stats['min']:.1f}Â°C | Max: {temp_stats['max']:.1f}Â°C")
            
            with col4:
                humidity_stats = df_filtered['Relative_Humidity'].describe()
                st.metric("Umidade MÃ©dia", f"{humidity_stats['mean']:.1f}%")
                st.caption(f"Min: {humidity_stats['min']:.1f}% | Max: {humidity_stats['max']:.1f}%")
        
    else:
        st.warning("âŒ Dados nÃ£o disponÃ­veis")
        st.info("ğŸ”„ Tente atualizar a pÃ¡gina ou verificar a conexÃ£o com a API")
    
    st.markdown("---")
    
    # SeÃ§Ã£o de alertas
    st.subheader("ğŸš¨ Alertas CrÃ­ticos")
    alerts_data = get_api_data("alerts")
    if alerts_data and alerts_data.get('alerts'):
        for alert in alerts_data['alerts']:
            st.error(f"âš ï¸ {alert.get('message', 'Alerta crÃ­tico')}")
    else:
        st.success("âœ… Nenhum alerta crÃ­tico")
    
    # Auto-refresh
    if auto_refresh:
        time.sleep(30)
        st.rerun()

if __name__ == "__main__":
    main()
